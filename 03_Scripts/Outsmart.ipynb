{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eoOtsnpOmSMO"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy.spatial import cKDTree\n",
        "from scipy.stats import zscore\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set Base Directory\n",
        "base_dir = Path.cwd().parent  # Moves one level up from current working directory\n",
        "\n",
        "# Data Directory\n",
        "data_dir = base_dir / '02_Data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "77s3XlNnm1Ic"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "train = pd.read_csv(data_dir / \"Train.csv\")\n",
        "test = pd.read_csv(data_dir / \"Test.csv\")\n",
        "toilets = pd.read_csv(data_dir / \"toilets.csv\")\n",
        "waste_management = pd.read_csv(data_dir / \"waste_management.csv\")\n",
        "water_sources = pd.read_csv(data_dir / \"water_sources.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Non-null counts and Dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Train Data Info\\n\")\n",
        "train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Test Data Info\\n\")\n",
        "test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Number of Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Train Data - Number of Missing Values\\n\")\n",
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Test Data - Number of Missing Values\\n\")\n",
        "test.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicate_count = train.duplicated().sum()\n",
        "print(duplicate_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "duplicate_count_test = test.duplicated().sum()\n",
        "print(duplicate_count_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to plot boxplots for numerical features\n",
        "def plot_boxplots(df, title):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.boxplot(data=df.select_dtypes(include=['number']))\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Boxplots\n",
        "plot_boxplots(train, \"Boxplot of Numerical Features (Train Dataset)\")\n",
        "plot_boxplots(test, \"Boxplot of Numerical Features (Test Dataset)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outliers Using IQR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_outliers_iqr(data, multiplier=1.5):\n",
        "    \"\"\"Detects outliers in a given Pandas Series using the IQR method.\"\"\"\n",
        "    q1 = np.percentile(data.dropna(), 25)\n",
        "    q3 = np.percentile(data.dropna(), 75)\n",
        "    IQR = q3 - q1\n",
        "    lwr_bound = q1 - (1.5 * IQR)\n",
        "    upr_bound = q3 + (multiplier * IQR)\n",
        "\n",
        "    return data[(data < lwr_bound) | (data > upr_bound)].index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Train Data - Summary Stats\\n\")\n",
        "\n",
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Test Data - Summary Stats\\n\")\n",
        "\n",
        "test.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Variable Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Plot target variable distribution\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# sns.histplot(train['Total'], bins=30, kde=True)\n",
        "# plt.title(\"Distribution of Total Variable\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Correlation in Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Select only numeric columns\n",
        "# numeric_cols = train.select_dtypes(include=['number'])\n",
        "\n",
        "# # Compute correlation only for numeric features\n",
        "# plt.figure(figsize=(12, 6))\n",
        "# sns.heatmap(numeric_cols.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "# plt.title(\"Feature Correlation Heatmap\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imputing with Median\n",
        "train.loc[:, 'Total'] = train['Total'].fillna(train['Total'].median())\n",
        "\n",
        "# Number of Missing Values\n",
        "train.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Duplicates, Skewness and Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_with_duplicates = train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Log_Total before detecting outliers\n",
        "train_with_duplicates[\"Log_Total\"] = np.log1p(train_with_duplicates[\"Total\"])\n",
        "\n",
        "train_with_duplicates[\"Z_Score_Total\"] = np.abs(zscore(train_with_duplicates[\"Total\"]))\n",
        "train_with_duplicates[\"Z_Score_Log_Total\"] = np.abs(zscore(train_with_duplicates[\"Log_Total\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outlier Detection Before Removing Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Using IQR\n",
        "outliers_iqr_with_duplicates = train_with_duplicates.loc[detect_outliers_iqr(train_with_duplicates[\"Total\"])]\n",
        "outliers_iqr_log_with_duplicates = train_with_duplicates.loc[detect_outliers_iqr(train_with_duplicates[\"Log_Total\"])]\n",
        "\n",
        "\n",
        "# Using Z-score\n",
        "outliers_zscore_with_duplicates = train_with_duplicates.loc[train_with_duplicates[\"Z_Score_Total\"] > 3]\n",
        "outliers_zscore_log_with_duplicates = train_with_duplicates.loc[train_with_duplicates[\"Z_Score_Log_Total\"] > 3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Removing Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop duplicate rows\n",
        "train = train.drop_duplicates()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outlier Detection After Removing Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Log_Total after dropping duplicates\n",
        "train[\"Log_Total\"] = np.log1p(train[\"Total\"])\n",
        "\n",
        "train[\"Z_Score_Total\"] = np.abs(zscore(train[\"Total\"]))\n",
        "train[\"Z_Score_Log_Total\"] = np.abs(zscore(train[\"Log_Total\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detect outliers using IQR on Total and Log_Total after dropping duplicates\n",
        "outliers_iqr_no_duplicates = train.loc[detect_outliers_iqr(train[\"Total\"])]\n",
        "outliers_iqr_log_no_duplicates = train.loc[detect_outliers_iqr(train[\"Log_Total\"])]\n",
        "\n",
        "\n",
        "# Detect outliers using Z-score on Total and Log_Total after dropping duplicates\n",
        "outliers_zscore_no_duplicates = train.loc[train[\"Z_Score_Total\"] > 3]\n",
        "outliers_zscore_log_no_duplicates = train.loc[train[\"Z_Score_Log_Total\"] > 3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "outlier_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Method\": [\"IQR\", \"Z-Score\"],\n",
        "        \"Total_With_Duplicates\": [outliers_iqr_with_duplicates.shape[0], outliers_zscore_with_duplicates.shape[0]],\n",
        "        \"Total_No_Duplicates\": [outliers_iqr_no_duplicates.shape[0], outliers_zscore_no_duplicates.shape[0]],\n",
        "        \"Log_Total_With_Duplicates\": [outliers_iqr_log_with_duplicates.shape[0], outliers_zscore_log_with_duplicates.shape[0]],\n",
        "        \"Log_Total_No_Duplicates\": [outliers_iqr_log_no_duplicates.shape[0], outliers_zscore_log_no_duplicates.shape[0]]\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Number of Outliers With and Without Duplicates in Total and Log_Total\")\n",
        "\n",
        "outlier_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Data Set (Review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train = train.drop([\"Z_Score_Total\",\"Z_Score_Log_Total\"], axis=1)\n",
        "# train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Impute Outliers with Median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_no_outliers = train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Impute IQR outliers with median\n",
        "for col in [\"Total\", \"Log_Total\"]:\n",
        "    median_value = train_no_outliers[col].median()\n",
        "    train_no_outliers.loc[detect_outliers_iqr(train_no_outliers[col]), col] = median_value\n",
        "\n",
        "# Impute Z-score outliers with median\n",
        "for col in [\"Total\", \"Log_Total\"]:\n",
        "    median_value = train_no_outliers[col].median()\n",
        "    train_no_outliers.loc[train_no_outliers[f\"Z_Score_{col}\"] > 3, col] = median_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Detect Outliers Again After Imputation\n",
        "outliers_iqr_after = {\n",
        "    \"Total\": len(detect_outliers_iqr(train_no_outliers[\"Total\"])),\n",
        "    \"Log_Total\": len(detect_outliers_iqr(train_no_outliers[\"Log_Total\"]))\n",
        "}\n",
        "\n",
        "outliers_zscore_after = {\n",
        "    \"Total\": (train_no_outliers[\"Z_Score_Total\"] > 3).sum(),\n",
        "    \"Log_Total\": (train_no_outliers[\"Z_Score_Log_Total\"] > 3).sum()\n",
        "}\n",
        "\n",
        "# Step 2: Create DataFrame to Compare Outliers Before and After Imputation\n",
        "outliers_after_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Method\": [\"IQR\", \"Z-Score\"],\n",
        "        \"Total_After_Imputation\": [outliers_iqr_after[\"Total\"], outliers_zscore_after[\"Total\"]],\n",
        "        \"Log_Total_After_Imputation\": [outliers_iqr_after[\"Log_Total\"], outliers_zscore_after[\"Log_Total\"]]\n",
        "    }\n",
        ")\n",
        "\n",
        "# Step 3: Print Results\n",
        "print(\"Outliers Remaining After Imputation:\")\n",
        "print(outliers_after_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### More Preprocessing - Merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Backup\n",
        "train_backup = train.copy()\n",
        "test_backup = test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check column names for all datasets\n",
        "print(\"Train Columns:\", train.columns)\n",
        "print(\"Test Columns:\", test.columns)\n",
        "print(\"Toilets Columns:\", toilets.columns)\n",
        "print(\"Waste Management Columns:\", waste_management.columns)\n",
        "print(\"Water Sources Columns:\", water_sources.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Next Steps\n",
        "- I'll merge train and test with the other datasets.\n",
        "- Before that, I'll add a prefix like the starter notebook but instead of using the engineered \"Month_Year_lat_lon\", I'll take the orginal columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to add prefixes while keeping essential merge keys unchanged\n",
        "def add_prefix(df, prefix, exclude_cols=[\"Location\", \"Year\", \"Month\", \"Transformed_Latitude\", \"Transformed_Longitude\"]):\n",
        "    \"\"\"Renames columns by adding a prefix while keeping essential merge keys unchanged.\"\"\"\n",
        "    df = df.rename(columns={col: f\"{prefix}_{col}\" for col in df.columns if col not in exclude_cols})\n",
        "    return df\n",
        "\n",
        "# Apply prefixes to each auxiliary dataset\n",
        "toilets_prefixed = add_prefix(toilets, \"toilet\")\n",
        "waste_management_prefixed = add_prefix(waste_management, \"waste\")\n",
        "water_sources_prefixed = add_prefix(water_sources, \"water\")\n",
        "\n",
        "# Verify changes\n",
        "print(\"Toilets Columns:\", toilets_prefixed.columns)\n",
        "print(\"Waste Management Columns:\", waste_management_prefixed.columns)\n",
        "print(\"Water Sources Columns:\", water_sources_prefixed.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZB6-U9UnhC_"
      },
      "source": [
        "## Start modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1GslRNGqOXE"
      },
      "source": [
        "#### Make predictions on test"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "zindienv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
